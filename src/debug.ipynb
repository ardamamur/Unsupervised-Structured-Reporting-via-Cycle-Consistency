{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses.Losses import *\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = transforms.ToTensor()\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to 3-channel grayscale\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = \"/home/max/Desktop/MLMI/data/mimic-cxr-jpg/files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg\"\n",
    "gt_image_path = \"/home/max/Desktop/MLMI/data/mimic-cxr-jpg/files/p10/p10000764/s57375967/096052b7-d256dc40-453a102b-fa7d01c6-1b22c6b4.jpg\"\n",
    "test_image = Image.open(test_image_path)\n",
    "test_image = transform(test_image)\n",
    "gt_image = Image.open(gt_image_path)\n",
    "gt_image = transform(gt_image)\n",
    "test_image = test_image.unsqueeze(0)  # Add a batch dimension\n",
    "gt_image = gt_image.unsqueeze(0)      # Add a batch dimension\n",
    "print(gt_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptual_loss = Loss('biovil_t')\n",
    "# perceptual_loss = Loss('biovil')\n",
    "# perceptual_loss = Loss('ark', reference_path=None)\n",
    "# perceptual_loss = Loss('vgg')\n",
    "# perceptual_loss = Loss('style_vgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_0 = perceptual_loss(gt_image, gt_image)\n",
    "loss_1 = perceptual_loss(gt_image, test_image)\n",
    "loss_2 = perceptual_loss(test_image, test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'gt_vs_gt: {loss_0}')\n",
    "print(f'gt_vs_test: {loss_1}')\n",
    "print(f'gt_vs_test: {loss_2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
