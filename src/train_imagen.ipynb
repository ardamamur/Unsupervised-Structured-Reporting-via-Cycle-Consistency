{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.imagen_pytorch.imagen_pytorch import Unet, Imagen\n",
    "from models.imagen_pytorch.trainer import ImagenTrainer\n",
    "from models.imagen_pytorch.data import NLMCXRDataset\n",
    "from models.imagen_pytorch.t5 import t5_encode_text, get_encoded_dim, DEFAULT_T5_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unets for unconditional imagen\n",
    "\n",
    "unet = Unet(\n",
    "    dim = 32,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = 1,\n",
    "    layer_attns = (False, False, False, True),\n",
    "    layer_cross_attns = False\n",
    ")\n",
    "\n",
    "# imagen, which contains the unet above\n",
    "\n",
    "imagen = Imagen(\n",
    "    condition_on_text = True,  # this must be set to False for unconditional Imagen\n",
    "    unets = unet,\n",
    "    image_sizes = 64,\n",
    "    timesteps = 1000,\n",
    "    channels=1,\n",
    "    cond_drop_prob = 0.1\n",
    ")\n",
    "\n",
    "trainer = ImagenTrainer(\n",
    "    imagen = imagen,\n",
    "    split_valid_from_train = False, # whether to split the validation dataset from the training\n",
    ").cuda()\n",
    "\n",
    "# instantiate your dataloader, which returns the necessary inputs to the DDPM as tuple in the order of images, text embeddings, then text masks. in this case, only images is returned as it is unconditional training\n",
    "texts = [f'example text {i}' for i in range(10)]\n",
    "\n",
    "text_embeds, text_masks = t5_encode_text(texts, DEFAULT_T5_NAME, return_attn_mask=True)\n",
    "dataset_train = NLMCXRDataset('/home/guo/git/Rad-ReStruct/data/radrestruct/images/', '/home/guo/data/ecgen-radiology/', image_size=64, mode='train')\n",
    "dataset_val = NLMCXRDataset('/home/guo/git/Rad-ReStruct/data/radrestruct/images/', '/home/guo/data/ecgen-radiology/', image_size=64, mode='val')\n",
    "\n",
    "\n",
    "trainer.add_train_dataset(dataset_train, batch_size = 16)\n",
    "trainer.add_valid_dataset(dataset_val, batch_size = 16)\n",
    "\n",
    "# working training loop\n",
    "\n",
    "for i in range(200000):\n",
    "    loss = trainer.train_step(unet_number = 1, max_batch_size = 64)\n",
    "    # print(f'loss: {loss}')\n",
    "\n",
    "    if not (i % 50):\n",
    "        valid_loss = trainer.valid_step(unet_number = 1, max_batch_size = 4)\n",
    "        print(f'valid loss in {i}: {valid_loss}')\n",
    "\n",
    "    if not (i % 500) and trainer.is_main: # is_main makes sure this can run in distributed\n",
    "        images = trainer.sample(batch_size = 1, return_pil_images = True, text_embeds=text_embeds) # returns List[Image]\n",
    "        images[0].save(f'../tmp/sample-{i // 100}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radrestruct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
